Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using RobertaForSequenceClassification ...
Vocab size: 50265
Load weight patial done !
Loading Pretain Model done!
Freeze Backboned layers
the number of freezing layers 8
dataset : CLINC150
len of datasets : 750
the numbers of intents 150
the number of maximum of batching : 47
DataLoader Done !
lamda : 0.05
temperature : 0.3
name on tensorboard: Load=True_roberta-base_21_12_2021_15:42_B=16_lr _5e-06_lambda=0.05_temp=0.3
----------
: before norm vect :
h_i : tensor([[ 0.1443, -0.3716],
        [-0.2707,  0.1345]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.2549, -0.6982],
        [ 0.0970,  0.9219]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.2877, -0.6263],
        [-0.4662,  0.0972]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0068, -0.0175],
        [-0.0128,  0.0064]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0085, -0.0233],
        [ 0.0032,  0.0307]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0055, -0.0119],
        [-0.0088,  0.0018]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([3, 1])
pos_sim.shape : torch.Size([3])
len(neg) : 3
loss_s_cl: tensor(0.9940, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.2526, -0.0887]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0955, -0.4522]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.1294,  0.0129],
        [ 0.5614, -0.1256]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0278, -0.0098]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0099, -0.0467]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0021,  0.0002],
        [ 0.0092, -0.0021]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.2683, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.1491,  0.4073]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.3153,  0.2938]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.4140,  0.1657],
        [-0.0413,  0.0909]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0153,  0.0417]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0278,  0.0259]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0079,  0.0032],
        [-0.0008,  0.0017]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.1815, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.1264,  0.4085]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.2226,  0.4537]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.9969,  0.6173],
        [-0.3355,  0.3636]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0103,  0.0333]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0200,  0.0408]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0165,  0.0102],
        [-0.0055,  0.0060]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.3105, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.3221, -0.4403]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.3398,  0.1790]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.1870,  0.4001],
        [ 0.3566, -0.0950]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0152, -0.0207]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0326,  0.0172]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0033,  0.0070],
        [ 0.0062, -0.0017]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.3818, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.1787,  0.9136],
        [-0.5469,  0.0160]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.3051,  0.1470],
        [-0.6675, -0.0052]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.1040, -0.3528],
        [ 0.1787,  0.9136]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0095,  0.0485],
        [-0.0290,  0.0008]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0193,  0.0093],
        [-0.0421, -0.0003]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0022, -0.0074],
        [ 0.0037,  0.0190]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(2.0489, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.5657, -0.3453],
        [-0.5657, -0.3453]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.1859,  0.5744],
        [-0.0293, -0.7418]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.3048,  0.4055],
        [ 0.0962, -0.3812]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0320, -0.0195],
        [-0.0320, -0.0195]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0116,  0.0358],
        [-0.0018, -0.0463]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0059,  0.0079],
        [ 0.0019, -0.0074]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(2.0414, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.1679, -0.0976]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.2598, -0.5879]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.1784, -0.0482],
        [ 0.2999,  0.4015]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0163, -0.0094]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0260, -0.0590]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0036, -0.0010],
        [ 0.0060,  0.0081]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.3833, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.0202, -0.0975],
        [-0.6320,  0.1284]], grad_fn=<SliceBackward>)
h_j : tensor([[-1.0677,  0.3467],
        [-0.2035,  0.2694]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.1298,  0.3602],
        [-0.0711,  0.2104]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0013, -0.0063],
        [-0.0407,  0.0083]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0421,  0.0137],
        [-0.0080,  0.0106]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0024,  0.0068],
        [-0.0013,  0.0039]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(2.1095, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[0.0212, 0.1473]], grad_fn=<SliceBackward>)
h_j : tensor([[0.4356, 0.3968]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.5819,  0.1551],
        [-0.0412,  0.4844]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[0.0016, 0.0111]], grad_fn=<SliceBackward>)
h_j : tensor([[0.0255, 0.0233]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0120,  0.0032],
        [-0.0008,  0.0100]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.1041, grad_fn=<DivBackward0>)

[1,    10] loss_total: 41.546 loss_supervised_contrasive:  3.882 loss_intent :753.281 
skip_time: 0
total : 10
----------
: before norm vect :
h_i : tensor([[-0.2388, -0.8452],
        [ 0.0312,  0.6020]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.1369, -0.2742],
        [ 0.1490,  0.5872]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.3294, -0.2913],
        [-0.0674,  0.5024]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0138, -0.0487],
        [ 0.0018,  0.0347]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0070, -0.0140],
        [ 0.0076,  0.0300]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0063, -0.0056],
        [-0.0013,  0.0097]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(1.8204, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.0245,  0.1612],
        [-1.0093,  0.7656]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0022, -0.2375],
        [-0.5983,  0.3745]], grad_fn=<SliceBackward>)
h_n : tensor([[0.0245, 0.1612],
        [0.0179, 0.0570]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0008,  0.0053],
        [-0.0333,  0.0253]], grad_fn=<SliceBackward>)
h_j : tensor([[ 9.0151e-05, -9.7960e-03],
        [-2.4674e-02,  1.5443e-02]], grad_fn=<SliceBackward>)
h_n : tensor([[0.0004, 0.0027],
        [0.0003, 0.0010]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(1.9254, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.1665,  0.3965],
        [-0.1665,  0.3965]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.1314,  0.5918],
        [-0.2583,  0.6107]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0801,  0.2319],
        [-0.2634,  0.0382]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0096,  0.0229],
        [-0.0096,  0.0229]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0042,  0.0190],
        [-0.0083,  0.0196]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0014,  0.0041],
        [-0.0047,  0.0007]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([3, 1])
pos_sim.shape : torch.Size([3])
len(neg) : 3
loss_s_cl: tensor(0.9641, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.0082, -0.3054]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0473, -0.0591]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.5306, -0.1110],
        [-0.0598,  0.1569]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0007, -0.0277]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0040, -0.0050]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0087, -0.0018],
        [-0.0010,  0.0026]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.1828, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.0566,  0.0596],
        [-0.4987, -0.0647]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0507,  0.2333],
        [-0.2657,  0.0079]], grad_fn=<SliceBackward>)
h_n : tensor([[0.0566, 0.0596],
        [0.4763, 0.4319]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0021,  0.0022],
        [-0.0181, -0.0023]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0018,  0.0083],
        [-0.0094,  0.0003]], grad_fn=<SliceBackward>)
h_n : tensor([[0.0009, 0.0010],
        [0.0078, 0.0071]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([3, 1])
pos_sim.shape : torch.Size([3])
len(neg) : 3
loss_s_cl: tensor(0.9279, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 1.0499e+00, -1.7309e-01],
        [-2.2646e-04, -4.3192e-01]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.1971, -0.4829],
        [ 0.0564,  0.0759]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.1627, -0.0663],
        [-0.0926, -0.5105]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 4.6456e-02, -7.6586e-03],
        [-1.0020e-05, -1.9111e-02]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0076, -0.0186],
        [ 0.0022,  0.0029]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0030, -0.0012],
        [-0.0017, -0.0093]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(1.9146, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.4204, -0.1112]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.3616, -0.2146]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.4204, -0.1112],
        [ 0.0619,  0.3904]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0254, -0.0067]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0361, -0.0214]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0082, -0.0022],
        [ 0.0012,  0.0077]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.3703, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.2624,  0.0844],
        [ 0.0948,  0.7373]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.3637,  0.5463],
        [-0.1449,  0.6873]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.1758, -0.3704],
        [ 0.0043,  0.1544]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0186,  0.0060],
        [ 0.0067,  0.0522]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0187,  0.0281],
        [-0.0074,  0.0353]], grad_fn=<SliceBackward>)
h_n : tensor([[ 3.3168e-03, -6.9878e-03],
        [ 8.1167e-05,  2.9123e-03]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(1.9006, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.0849, -0.0383],
        [ 0.2116,  0.2932]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.1745, -0.4056],
        [ 0.2305,  0.3363]], grad_fn=<SliceBackward>)
h_n : tensor([[0.0158, 0.0953],
        [0.2992, 0.5915]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0056, -0.0025],
        [ 0.0140,  0.0194]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0118, -0.0274],
        [ 0.0156,  0.0228]], grad_fn=<SliceBackward>)
h_n : tensor([[0.0004, 0.0022],
        [0.0069, 0.0136]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(1.7884, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.0681,  0.0297]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0659,  0.2675]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.1766,  0.1879],
        [-0.3895, -0.3234]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0065,  0.0028]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0077,  0.0313]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0037,  0.0040],
        [-0.0082, -0.0068]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.0726, grad_fn=<DivBackward0>)

[1,    20] loss_total: 40.351 loss_supervised_contrasive:  6.569 loss_intent :1506.574 
skip_time: 0
total : 20
----------
: before norm vect :
h_i : tensor([[0.0582, 0.6114],
        [0.2516, 0.0489]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.5709, -0.1802],
        [ 0.2786,  0.1242]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0564, -0.4818],
        [-0.0166,  0.0348]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[0.0033, 0.0343],
        [0.0141, 0.0027]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0319, -0.0101],
        [ 0.0156,  0.0069]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0011, -0.0093],
        [-0.0003,  0.0007]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(1.8761, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.1104,  0.3481],
        [ 0.0736,  0.1454]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0468, -0.2341],
        [-0.1307,  0.0189]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.1104,  0.3481],
        [ 0.0736,  0.1454]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0081,  0.0255],
        [ 0.0054,  0.0107]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0030, -0.0151],
        [-0.0084,  0.0012]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0025,  0.0080],
        [ 0.0017,  0.0034]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(2.0144, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.0808, -0.1798],
        [-0.0613,  0.7676]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0555, -0.0134],
        [-0.0553,  0.3640]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.1395, -0.3231],
        [-0.0808, -0.1798]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0033, -0.0074],
        [-0.0025,  0.0318]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0042, -0.0010],
        [-0.0042,  0.0275]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0029, -0.0066],
        [-0.0017, -0.0037]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(1.8975, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.1278,  0.0497],
        [-0.3939, -0.4072]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.2021,  0.1322],
        [ 0.0276, -0.4923]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0007,  0.0091],
        [-0.1763,  0.4110]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0065,  0.0025],
        [-0.0200, -0.0207]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0108,  0.0071],
        [ 0.0015, -0.0263]], grad_fn=<SliceBackward>)
h_n : tensor([[-1.4944e-05,  1.9710e-04],
        [-3.8257e-03,  8.9181e-03]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([3, 1])
pos_sim.shape : torch.Size([3])
len(neg) : 3
loss_s_cl: tensor(1.0126, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.5698,  0.9797],
        [-0.0931,  0.0050]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.3890,  0.6040],
        [-0.1798,  0.9963]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0697,  0.1902],
        [ 0.0973,  0.2693]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0209,  0.0360],
        [-0.0034,  0.0002]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0123,  0.0192],
        [-0.0057,  0.0316]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0013,  0.0036],
        [ 0.0019,  0.0052]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([4, 1])
pos_sim.shape : torch.Size([4])
len(neg) : 4
loss_s_cl: tensor(0.5900, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.0262,  0.9974]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0275,  0.6981]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.1090,  0.2533],
        [ 0.3179,  0.1422]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0016,  0.0619]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0029,  0.0740]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0022,  0.0050],
        [ 0.0063,  0.0028]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.2196, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.0922, -0.2581]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0056, -0.2665]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0669, -0.0255],
        [ 0.0922, -0.2581]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0075, -0.0209]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0003, -0.0126]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0012, -0.0004],
        [ 0.0016, -0.0045]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(4.8190, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.3710,  0.1574],
        [-0.9586,  0.1402]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.4122,  0.2820],
        [-1.3172,  0.2982]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0038,  0.1109],
        [-0.1745, -0.5058]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0209,  0.0088],
        [-0.0539,  0.0079]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0164,  0.0112],
        [-0.0524,  0.0119]], grad_fn=<SliceBackward>)
h_n : tensor([[-7.2738e-05,  2.1162e-03],
        [-3.3308e-03, -9.6517e-03]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(1.7496, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.3174,  0.0833]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.9912,  0.1159]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.1686,  0.0837],
        [-0.2256, -0.1845]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0149,  0.0039]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0608,  0.0071]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0033,  0.0016],
        [-0.0044, -0.0036]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(4.7977, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.1953,  0.1455],
        [ 0.4870,  0.5492]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.3996, -0.1108],
        [ 0.0794,  0.0530]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.1953,  0.1455],
        [ 0.4222, -1.4107]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0081,  0.0061],
        [ 0.0203,  0.0229]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0286, -0.0079],
        [ 0.0057,  0.0038]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0035,  0.0026],
        [ 0.0075, -0.0251]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(1.9529, grad_fn=<DivBackward0>)

[1,    30] loss_total: 40.250 loss_supervised_contrasive:  9.162 loss_intent :2259.711 
skip_time: 0
total : 30
----------
: before norm vect :
h_i : tensor([[ 0.4911, -0.2297]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.3875, -0.0541]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.1141, -0.1369],
        [-0.0498, -0.1826]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0438, -0.0205]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0343, -0.0048]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0022, -0.0027],
        [-0.0010, -0.0036]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.4017, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.0343, -0.4434]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0678, -0.3568]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.1592,  0.2273],
        [ 0.0552, -0.2724]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0035, -0.0458]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0065, -0.0344]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0033,  0.0046],
        [ 0.0011, -0.0056]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(4.8193, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.0754,  0.3180]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.2268,  0.3627]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.4368,  0.2059],
        [ 0.4515, -0.1436]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0035,  0.0149]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0179,  0.0287]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0078,  0.0037],
        [ 0.0080, -0.0026]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.5535, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.0879, -0.3785],
        [-0.1899,  0.2569]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0726, -0.1167],
        [-0.1037, -0.0502]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.3031,  0.1277],
        [ 0.4039, -0.1846]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0056, -0.0243],
        [-0.0122,  0.0165]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0032, -0.0052],
        [-0.0046, -0.0022]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0068,  0.0029],
        [ 0.0090, -0.0041]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(1.8201, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.0593,  0.1537]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.6048,  0.1031]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.7043, -0.1878],
        [-0.0593,  0.1537]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0057,  0.0147]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0595,  0.0101]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0145, -0.0039],
        [-0.0012,  0.0032]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.5337, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.3506,  0.1830],
        [-0.1192, -0.2518]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0031,  0.3644],
        [-0.0162, -0.0038]], grad_fn=<SliceBackward>)
h_n : tensor([[0.0020, 0.0836],
        [0.0340, 0.2669]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0173,  0.0090],
        [-0.0059, -0.0124]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0001,  0.0171],
        [-0.0008, -0.0002]], grad_fn=<SliceBackward>)
h_n : tensor([[4.5889e-05, 1.8798e-03],
        [7.6365e-04, 5.9987e-03]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([3, 1])
pos_sim.shape : torch.Size([3])
len(neg) : 3
loss_s_cl: tensor(0.9519, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.0530, -0.0748],
        [-0.0248, -0.0521]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.3115, -0.0739],
        [-0.1402, -0.6845]], grad_fn=<SliceBackward>)
h_n : tensor([[0.3318, 0.2449],
        [0.0175, 0.3626]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0036, -0.0051],
        [-0.0017, -0.0036]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0134, -0.0032],
        [-0.0060, -0.0294]], grad_fn=<SliceBackward>)
h_n : tensor([[0.0074, 0.0055],
        [0.0004, 0.0081]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(1.8695, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.1312, -0.2607]], grad_fn=<SliceBackward>)
h_j : tensor([[0.1459, 0.0652]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.4128,  0.4145],
        [ 0.2544, -0.0949]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0164, -0.0325]], grad_fn=<SliceBackward>)
h_j : tensor([[0.0181, 0.0081]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0090,  0.0090],
        [ 0.0055, -0.0021]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.1538, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.0533, -0.4551]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0016, -0.6056]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.1389,  0.5075],
        [-0.2907,  0.1653]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0052, -0.0442]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0002, -0.0587]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0031,  0.0113],
        [-0.0065,  0.0037]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(4.8107, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.1528,  0.1306]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0244, -0.1833]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0431, -0.4736],
        [-0.0945,  0.1920]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0119,  0.0102]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0024, -0.0177]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0009, -0.0099],
        [-0.0020,  0.0040]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.0576, grad_fn=<DivBackward0>)

[1,    40] loss_total: 41.744 loss_supervised_contrasive:  13.259 loss_intent :3012.655 
skip_time: 0
total : 40
----------
: before norm vect :
h_i : tensor([[-0.3593,  0.2893]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.6613, -0.0258]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.1775, -0.3072],
        [ 0.3313,  0.0551]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0272,  0.0219]], grad_fn=<SliceBackward>)
h_j : tensor([[ 0.0307, -0.0012]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0032, -0.0055],
        [ 0.0059,  0.0010]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.3045, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[0.1776, 0.1591]], grad_fn=<SliceBackward>)
h_j : tensor([[0.1799, 0.2029]], grad_fn=<SliceBackward>)
h_n : tensor([[0.4977, 0.8715],
        [0.0084, 0.0018]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[0.0227, 0.0203]], grad_fn=<SliceBackward>)
h_j : tensor([[0.0248, 0.0279]], grad_fn=<SliceBackward>)
h_n : tensor([[1.0625e-02, 1.8604e-02],
        [1.7988e-04, 3.8081e-05]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(4.8055, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.0859, -0.0121]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0851,  0.0323]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.4009,  0.2162],
        [-0.2593, -0.0581]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0077, -0.0011]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0068,  0.0026]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0080,  0.0043],
        [-0.0052, -0.0012]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(4.9556, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.1556, -0.1744],
        [ 0.5137, -0.1002]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0726, -0.1220],
        [ 1.0950,  0.1272]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0136, -0.0826],
        [-0.2948, -0.1443]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0075, -0.0084],
        [ 0.0246, -0.0048]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0035, -0.0059],
        [ 0.0527,  0.0061]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0003, -0.0019],
        [-0.0067, -0.0033]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([4, 1])
pos_sim.shape : torch.Size([4])
len(neg) : 4
loss_s_cl: tensor(0.5786, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.2845,  0.1697],
        [-0.0077, -0.4659]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.1961,  0.0326],
        [ 0.0210, -0.2880]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.2845,  0.1697],
        [ 0.1136,  0.2880]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0171,  0.0102],
        [-0.0005, -0.0280]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0140,  0.0023],
        [ 0.0015, -0.0206]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0059,  0.0035],
        [ 0.0023,  0.0059]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([2, 1])
pos_sim.shape : torch.Size([2])
len(neg) : 2
loss_s_cl: tensor(1.8150, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[-0.1632,  0.1758]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.2842, -0.2833]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.2372, -0.0786],
        [-0.3995, -0.1169]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[-0.0160,  0.0172]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0351, -0.0350]], grad_fn=<SliceBackward>)
h_n : tensor([[-0.0050, -0.0017],
        [-0.0084, -0.0025]], grad_fn=<SliceBackward>)
res.shape : torch.Size([16, 16])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.1476, grad_fn=<DivBackward0>)

----------
: before norm vect :
h_i : tensor([[ 0.2378, -0.1180]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.1529,  0.1711]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0408, -0.8187],
        [ 0.8713,  0.0928]], grad_fn=<SliceBackward>)
norm vect
h_i : tensor([[ 0.0249, -0.0123]], grad_fn=<SliceBackward>)
h_j : tensor([[-0.0192,  0.0215]], grad_fn=<SliceBackward>)
h_n : tensor([[ 0.0009, -0.0188],
        [ 0.0200,  0.0021]], grad_fn=<SliceBackward>)
res.shape : torch.Size([14, 14])
after summing res.shape : torch.Size([])
neg_sim.shape : torch.Size([1, 1])
pos_sim.shape : torch.Size([1])
len(neg) : 1
loss_s_cl: tensor(5.2701, grad_fn=<DivBackward0>)

deleate logger for one combination
../../models/Load=True_roberta-base_B=16_lr=5e-06_21_12_2021_15:41.pth
Finished Training
Saving Done !
