{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57578c42-10c1-4187-bc41-007d70b3ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import numpy as np\n",
    "from utils import loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f683e-720f-4bf1-aa42-68a0a13011ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-Shot Intent Detection via Contrastive Pre-Training and Fine-Tuning\n",
    "# https://github.com/jianguoz/Few-Shot-Intent-Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0291fadc-cbce-40e3-9912-0bb20e147e90",
   "metadata": {},
   "source": [
    "## Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c417745d-a746-44a2-ab5b-10ef0ae9274b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATIS  BANKING77  BANKING77-OOS\tCLINC150  CLINC-Single-Domain-OOS  HWU64  SNIPS\n"
     ]
    }
   ],
   "source": [
    "!ls ../../dataset/Few-Shot-Intent-Detection/Datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0822ef-a934-4c68-9210-f68b847d4007",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "- N - number of sentences in the batch \n",
    "- t - temperature paramter -> control penalty for neg samples\n",
    "- u - sentecnce or utterances \n",
    "- hi - representation of ui\n",
    "- hi - BERT(ui) -> we use bert-base-uncased\n",
    "- i-th -> order of sentence\n",
    "- hi_bar -> the representation of ui_bar \n",
    "- ui_bar -> the same sentence as ui but (10%) tokens are random masked  (Devlin et al.,2019)\n",
    "- M - the number of maksed tokens in each batch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcbfec1-08df-4d40-aeeb-e6692764e44f",
   "metadata": {},
   "source": [
    "## Preprocessesing data\n",
    "  Todo \n",
    "  1. dont forget to remove utterances that less than five tokens\n",
    "  2. we will all exclude  CLINC-Single-Domain-OOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7364f8cd-a722-4615-b700-749e4876f8cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trainning process\n",
    " 1. during batch trainning dont forget to randomly maksed, a sentence has \n",
    "    different maksed postion across different trannig epochs\n",
    " 2. (ui ,ui_bar) -> single encoder during batch tranning  (Gao et al., 2021)\n",
    " 3. add mask language modelling loss  (Devlinet al., 2019; Wu et al., 2020a)\n",
    " 4. P(xm) -> predicted probabilty of maksed token xm over total vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7825be64-c865-4b14-a905-a700e696692b",
   "metadata": {},
   "source": [
    "## Experiment Setting\n",
    "- contrasive Pretraining \n",
    " 1. Pre-train the combined intent datasets -> combine every dataset (guess)\n",
    " 2. 15 epochs\n",
    " 3. batch size = 64\n",
    " 4. t = 0.1 , lamda = 1.0\n",
    "\n",
    "- Fine tunning \n",
    " 1. 5-shot -> five trainning examples per intents\n",
    " 2. 10-shot -> tens trainning examples per intents\n",
    " 3. batch size = 16\n",
    " 4. t =  {0.1, 0.3, 0.5}\n",
    " 5. λ ∈ {0.01, 0.03, 0.05}\n",
    " 6. 30 epochs\n",
    " 7. apply label smoothing to the intent classifcation loss (Zhang et al. (2020a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea7425-c147-468c-b38f-4639e52d1789",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Pretrain model from vocabuary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51d2517a-c1b0-420a-86ca-09ab3120a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17b4852-25c6-461d-9271-94223363833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize input \n",
    "text = \"who was Elon musk ? Elon musk was an entrepreneur and business magnate\"\n",
    "tokenized_text = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9330c8fd-1c14-4268-b917-31b652e627e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask a token that we will try to predict with MLM\n",
    "masked_index = 7\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "#assert tokenized_text == [who was Elon musk ? Elon musk was an entrepreneur 'and','business','magnate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1220adb3-a5fb-4c85-a135-d285dfacfc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['who',\n",
       " 'was',\n",
       " 'el',\n",
       " '##on',\n",
       " 'mu',\n",
       " '##sk',\n",
       " '?',\n",
       " '[MASK]',\n",
       " '##on',\n",
       " 'mu',\n",
       " '##sk',\n",
       " 'was',\n",
       " 'an',\n",
       " 'entrepreneur',\n",
       " 'and',\n",
       " 'business',\n",
       " 'magnate']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tokenized_text))\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "436f5386-6a4f-4884-9f62-62a8b42ef61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Define sentence A and B indices associated to 1st and 2nd \n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09447ce1-bef6-4dc9-80f2-513787ffff3c",
   "metadata": {},
   "source": [
    "## Load weight Pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43a4a138-5df4-49c1-8c42-b528fb0c943a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval done\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "print(\"eval done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce267f1-0e3c-47c3-8156-519f55445d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\n",
    "encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba38990a-06d7-4235-afb2-0d9d58efe3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a hidden states for each of the 12 layers in model bert-base-uncased\n",
    "assert len(encoded_layers) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8bfb2ee-fbb6-4b99-b8c0-a553680b5182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# Predict all tokens\n",
    "predictions = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "# confirm we were able to predict 'henson'\n",
    "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n",
    "#assert predicted_token == 'musk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f340a30-6bd8-4e09-97d6-e92f438451bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['el']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a25429-437e-4830-becf-323dd7e38d31",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cf7a996-0ae8-4e59-bc5b-5470a28c9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 #None\n",
    "temperature = 0.5  #None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ac47bcf-7511-4611-888e-70682e5aa904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "36c4be35-757b-4a67-8711-401d5c7e9c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1464c4e6-2aa4-439f-97fb-cb83aeb744f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(3,2)\n",
    "b = np.random.rand(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c87e426-08d2-430e-b292-2f42482dde42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 2), (3, 2))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape , b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "96b19de9-13c9-44be-bc20-d2eb02607daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.92643996 1.70838819]\n",
      " [3.35620428 2.74840212]]\n",
      "9.7394345458278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_supervised_cl(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1e0bca-d5a3-4d9c-a586-5051b12097b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d0a2b-4af5-4d14-9750-d864a8d954a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
