# What Does Bert Look At ? An Analysis of BERT's Attetion 


 Adopt 
--- 
 what is specific language feature that they can use to help them discriminate intent  
 

ways of analysing 
--- 
 1) specific i/p and notice o/p 
 2) see vector represenation lool like 
 3) look at attetion head activate

 Guess
---
 
  show each attention part response to each i/p inside networks 


 question  
---
 How much each weight to each word when computation next word based on current word
