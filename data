# Datasets


1.Are Pretrained Transformers Robust in Intent Classification? A Missing Ingredient in Evaluation of Out-of-Scope Intent Detection


 CLINCâ€™s OOS <-> out-of-domain 

 OOS examples and the original Banking77 dataset


 OOS-OOS problem -> they cannot evaluate capability to detect OOS intents with same domains

 what are the targeted domains ? 

 OOD-OOS: out-of-domain OOS . General out-of-scope which are not supported by dialouge systems,also called out-of-domain eg. requesting NBA TV show service in banking system 

 
 ID-OOS: in-domain OOS, out-of-scope which are more related to in-scope intents <- challenge ! 
 eg. requesting a banking serviced that is not supported by the banking system. 

 :CLINIC dataset:
  - 10 domain select 15 intent for each
  - randomly select 2 domain from 10 domain to evaluate
                    L Banking
                    L Credit cards


 :The BANKING77: 
  
  - fined-grained single banking domain intent dataset with 77 intents
  
  - exclude OOS examples


  ** use to above dataset

     1) to detect OOS detection task 
     2) conduct the evaluation across dif domains and single larged fine-grained domain. 



5. Few-shot Intent Detection via Contrasive Pre-trainning and Fine-Tuning 

  *Pretrained datasets

   - detail datasets can be seen Table 1
   - they exclude test sets during Pretrained phase which is differetnt various work
   - they also remove utterances less than five tokens there are 80,782 trainning utterances 

  * Evaluation datasets 
     
   - CLINIC150
       L 23,700 10 domains
       L 150 intents

   - BANKING77 
       L 13,083 1 domain
       L 77 intents

   -  HUW64
       L 64 intents
       L 21 domains
